{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuImages devkit tutorial\n",
    "\n",
    "Welcome to the nuImages tutorial.\n",
    "This demo assumes the database itself is available at `/data/sets/nuimages`, and loads a mini version of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gentle Introduction to nuImages\n",
    "\n",
    "In this part of the tutorial, let us go through a top-down introduction of our database. Our dataset is structured as a relational database with tables, tokens and foreign keys. The tables are the following:\n",
    "\n",
    "1. `log` - Log from which the sample was extracted.\n",
    "2. `sample` - An annotated camera image with an associated timestamp and past and future images and pointclouds.\n",
    "3. `sample_data` - An image or pointcloud associated with a sample.\n",
    "4. `ego_pose` - The vehicle ego pose and timestamp associated with a sample_data.\n",
    "5. `sensor` - General information about a sensor, e.g. `CAM_BACK_LEFT`.\n",
    "6. `calibrated_sensor` - Calibration information of a sensor in a log.\n",
    "7. `category` - Taxonomy of object and surface categories (e.g. `vehicle.car`, `flat.driveable_surface`). \n",
    "8. `attribute` - Property of an object that can change while the category remains the same.\n",
    "9. `object_ann` - Bounding box and mask annotation of an object (e.g. car, adult).\n",
    "10. `surface_ann` - Mask annotation of a surface (e.g. `flat.driveable surface` and `vehicle.ego`).\n",
    "\n",
    "The database schema is visualized below. For more information see the [schema page](https://github.com/nutonomy/nuscenes-devkit/blob/master/docs/schema_nuimages.md).\n",
    "![](https://www.nuscenes.org/public/images/nuimages-schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab (optional)\n",
    "\n",
    "<br>\n",
    "<a href=\"https://colab.research.google.com/github/nutonomy/nuscenes-devkit/blob/master/python-sdk/tutorials/nuimages_tutorial.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\">\n",
    "</a>\n",
    "<br>\n",
    "    \n",
    "If you are running this notebook in Google Colab, you can uncomment the cell below and run it; everything will be set up nicely for you. Otherwise, manually set up everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/data’: Permission denied\n",
      "--2024-04-23 18:35:16--  https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz\n",
      "Resolving www.nuscenes.org (www.nuscenes.org)... 2600:9000:21c7:bc00:1b:5ef:6040:93a1, 2600:9000:21c7:2a00:1b:5ef:6040:93a1, 2600:9000:21c7:3200:1b:5ef:6040:93a1, ...\n",
      "Connecting to www.nuscenes.org (www.nuscenes.org)|2600:9000:21c7:bc00:1b:5ef:6040:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 117929607 (112M) [application/x-tar]\n",
      "Saving to: ‘nuimages-v1.0-mini.tgz’\n",
      "\n",
      "nuimages-v1.0-mini. 100%[===================>] 112,47M  84,9MB/s    in 1,3s    \n",
      "\n",
      "2024-04-23 18:35:17 (84,9 MB/s) - ‘nuimages-v1.0-mini.tgz’ saved [117929607/117929607]\n",
      "\n",
      "tar: /data/sets/nuimages: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /data/sets/nuimages  # Make the directory to store the nuImages dataset in.\n",
    "!wget https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz  # Download the nuImages mini split.\n",
    "\n",
    "!tar -xf nuimages-v1.0-mini.tgz -C /data/sets/nuimages  # Uncompress the nuImages mini split.\n",
    "!pip install nuscenes-devkit &> /dev/null  # Install nuImages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "To initialize the dataset class, we run the code below. We can change the dataroot parameter if the dataset is installed in a different folder. We can also omit it to use the default setup. These will be useful further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "======\n",
      "Loading nuImages tables for version v1.0-val...\n",
      "Done loading in 0.000 seconds (lazy=True).\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nuimages import NuImages\n",
    "\n",
    "#nuim = NuImages(dataroot='/home/robolab/Downloads/nuimages-v1.0-all-metadata', version='v1.0-train', verbose=True, lazy=True)\n",
    "#nuim = NuImages(dataroot='/home/robolab/Downloads/nuimages-v1.0-all-metadata', version='v1.0-test', verbose=True, lazy=True)\n",
    "nuim = NuImages(dataroot='/home/robolab/Downloads/nuimages-v1.0-all-metadata', version='v1.0-val', verbose=True, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "As described above, the NuImages class holds several tables. Each table is a list of records, and each record is a dictionary. For example the first record of the category table is stored at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 category(s) in 0.001s,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'token': '63a94dfa99bb47529567cd90d3b58384',\n",
       " 'name': 'animal',\n",
       " 'description': 'All animals, e.g. cats, rats, dogs, deer, birds.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuim.category[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the list of all tables, simply refer to the `table_names` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attribute',\n",
       " 'calibrated_sensor',\n",
       " 'category',\n",
       " 'ego_pose',\n",
       " 'log',\n",
       " 'object_ann',\n",
       " 'sample',\n",
       " 'sample_data',\n",
       " 'sensor',\n",
       " 'surface_ann']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuim.table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Since all tables are lists of dictionaries, we can use standard Python operations on them. A very common operation is to retrieve a particular record by its token. Since this operation takes linear time, we precompute an index that helps to access a record in constant time.\n",
    "\n",
    "Let us select the first image in this dataset version and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16445 sample(s) in 0.017s,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'token': '0001c87ad88847fb860b100a9ae77fc7',\n",
       " 'timestamp': 1533193855887005,\n",
       " 'log_token': 'e61048eefd0c4277b4bc077ef019e439',\n",
       " 'key_camera_token': '4ce15c90a085476db9023d85206e4042'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "sample = nuim.sample[sample_idx]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering\n",
    "\n",
    "To render an image we use the `render_image()` function. We can see the boxes and masks for each object category, as well as the surface masks for ego vehicle and driveable surface. We use the following colors:\n",
    "- vehicles: orange\n",
    "- bicycles and motorcycles: red\n",
    "- pedestrians: blue\n",
    "- cones and barriers: gray\n",
    "- driveable surface: teal / green\n",
    "\n",
    "At the top left corner of each box, we see the name of the object category (if `with_category=True`). We can also set `with_attributes=True` to print the attributes of each object (note that we can only set `with_attributes=True` to print the attributes of each object when `with_category=True`). In addition, we can specify if we want to see surfaces and objects, or only surfaces, or only objects, or neither by setting `with_annotations` to `all`, `surfaces`, `objects` and `none` respectively.\n",
    "\n",
    "Let us make the image bigger for better visibility by setting `render_scale=2`. We can also change the line width of the boxes using `box_line_width`. By setting it to -1, the line width adapts to the `render_scale`. Finally, we can render the image to disk using `out_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barrier': 0, 'bicycle': 1, 'bus': 2, 'car': 3, 'construction_vehicle': 4, 'motorcycle': 5, 'pedestrian': 6, 'traffic_cone': 7, 'trailer': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "def bbox2yolo(sizee, boxx):\n",
    "    dw = 1. / sizee[0]\n",
    "    dh = 1. / sizee[1]\n",
    "    x_center = (boxx[0] + boxx[1]) / 2.0\n",
    "    y_center = (boxx[2] + boxx[3]) / 2.0\n",
    "    width = boxx[1] - boxx[0]\n",
    "    height = boxx[3] - boxx[2]\n",
    "    \n",
    "    x_center = x_center * dw\n",
    "    width = width * dw\n",
    "    y_center = y_center * dh\n",
    "    height = height * dh\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (x_center, y_center, width, height)\n",
    "\n",
    "#now get the 'category_name' and assign a number instead \n",
    "classes = ['barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle', 'pedestrian', 'traffic_cone', 'trailer', 'truck']\n",
    "#make a dictionary where each class got a number\n",
    "class_dict = {classes[i]: i for i in range(len(classes))}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 213185 sample_data(s) in 0.732s,\n",
      "Loaded 213185 sample_data(s) in 2.947s,\n",
      "Loaded 213185 sample_data(s) in 3.477s,\n",
      "Loaded 213185 sample_data(s) in 4.786s,\n",
      "Loaded 213185 sample_data(s) in 4.882s,\n",
      "Loaded 213185 sample_data(s) in 4.811s,\n",
      "Loaded 213185 sample_data(s) in 8.840s,\n",
      "Loaded 213185 sample_data(s) in 9.425s,\n",
      "Loaded 213185 sample_data(s) in 9.585s,\n",
      "Loaded 213185 sample_data(s) in 11.262s,\n",
      "Loaded 213185 sample_data(s) in 12.321s,\n",
      "Loaded 213185 sample_data(s) in 12.320s,\n",
      "Loaded 213185 sample_data(s) in 12.449s,\n",
      "Loaded 213185 sample_data(s) in 12.878s,\n",
      "Loaded 213185 sample_data(s) in 13.045s,\n",
      "Loaded 213185 sample_data(s) in 14.554s,\n",
      "Loaded 213185 sample_data(s) in 15.934s,\n",
      "Loaded 213185 sample_data(s) in 16.009s,\n",
      "Loaded 213185 sample_data(s) in 16.153s,\n",
      "Loaded 213185 sample_data(s) in 16.775s,\n",
      "Loaded 213185 sample_data(s) in 16.850s,\n",
      "Loaded 213185 sample_data(s) in 16.789s,\n",
      "Loaded 213185 sample_data(s) in 16.947s,\n",
      "Loaded 213185 sample_data(s) in 17.725s,\n",
      "Loaded 213185 sample_data(s) in 17.752s,\n",
      "Loaded 213185 sample_data(s) in 18.388s,\n",
      "Loaded 213185 sample_data(s) in 18.476s,\n",
      "Loaded 213185 sample_data(s) in 18.399s,\n",
      "Loaded 213185 sample_data(s) in 18.568s,\n",
      "Loaded 136074 object_ann(s) in 0.811s,\n",
      "Loaded 136074 object_ann(s) in 2.884s,\n",
      "Loaded 136074 object_ann(s) in 1.912s,\n",
      "Loaded 136074 object_ann(s) in 2.521s,\n",
      "Loaded 136074 object_ann(s) in 3.331s,\n"
     ]
    }
   ],
   "source": [
    "#let's make a directory for the labels and images\n",
    "#labels_dir = '/home/robolab/Downloads/yolov9/train/labels' #for the train\n",
    "#images_dir = '/home/robolab/Downloads/yolov9/train/images'\n",
    "\n",
    "#labels_dir = '/home/robolab/Downloads/yolov9/test/labels' #for the test\n",
    "#images_dir = '/home/robolab/Downloads/yolov9/test/images'  \n",
    "\n",
    "labels_dir = '/home/robolab/Downloads/yolov9/val/labels' #for the val\n",
    "images_dir = '/home/robolab/Downloads/yolov9/val/images'  \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import concurrent.futures\n",
    "#now make it if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(labels_dir):\n",
    "    os.makedirs(labels_dir)\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "\n",
    "\n",
    "def process_sample(i):\n",
    "    sample = nuim.sample[i]\n",
    "    key_camera_token = sample['key_camera_token']\n",
    "    \n",
    "    # Render image using PyTorch\n",
    "    im, obj = nuim.render_image_2(\n",
    "        key_camera_token,\n",
    "        annotation_type='objects',\n",
    "        with_category=True,\n",
    "        with_attributes=True,\n",
    "        box_line_width=-1,\n",
    "        render_scale=5\n",
    "    )\n",
    "    \n",
    "    w, h = im.size\n",
    "    \n",
    "    # Convert image to PyTorch tensor\n",
    "    transform = T.ToTensor()\n",
    "    im_tensor = transform(im).unsqueeze(0).cuda()\n",
    "    \n",
    "    labels_data = []\n",
    "    \n",
    "    for obj_info in obj:\n",
    "        xmin, ymin, xmax, ymax = obj_info['bbox']\n",
    "        \n",
    "        # Convert bbox to YOLO format\n",
    "        bb = bbox2yolo((w, h), (xmin, xmax, ymin, ymax))\n",
    "        \n",
    "        category_name = obj_info['category_name']\n",
    "        \n",
    "        for class_name in classes:\n",
    "            if class_name in category_name:\n",
    "                labels_data.append(f\"{class_dict[class_name]} {' '.join(map(str, bb))}\\n\")\n",
    "                break\n",
    "                \n",
    "    with open(os.path.join(labels_dir, f\"{i}.txt\"), 'w') as f:\n",
    "        f.writelines(labels_data)\n",
    "    \n",
    "    im.save(os.path.join(images_dir, f\"{i}.png\"))\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "amount_samples = 8721810 # change to amount of samples in data, or just way to much and run until error\n",
    "\n",
    "# Parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(process_sample, range(amount_samples))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "#now get the 'category_name' and assign a number instead \n",
    "classes = ['barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle', 'pedestrian', 'traffic_cone', 'trailer', 'truck']\n",
    "#make a dictionary where each class got a number\n",
    "class_dict = {classes[i]: i for i in range(len(classes))}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def yolo2bbox(img_size, yolo_box):\n",
    "    \"\"\"\n",
    "    Convert YOLO format bounding box to bounding box coordinates.\n",
    "    \"\"\"\n",
    "    x, y, w, h = yolo_box\n",
    "    dw = 1. / img_size[0]\n",
    "    dh = 1. / img_size[1]\n",
    "    xmin = (x - w / 2.0) / dw\n",
    "    xmax = (x + w / 2.0) / dw\n",
    "    ymin = (y - h / 2.0) / dh\n",
    "    ymax = (y + h / 2.0) / dh\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# Randomly select and visualize a few images with bounding boxes\n",
    "num_images_to_display = 5\n",
    "selected_indices = np.random.choice(range(50), num_images_to_display, replace=False)  # change to 93000 on real dataset\n",
    "\n",
    "for i in selected_indices:\n",
    "    image_path = os.path.join(images_dir, f\"{i}.png\")\n",
    "    label_path = os.path.join(labels_dir, f\"{i}.txt\")\n",
    "    \n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    #now show the image without the bounding boxes first\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    w, h = image.size\n",
    "    \n",
    "    # Load labels\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Plot bounding boxes\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        yolo_box = tuple(map(float, parts[1:]))\n",
    "        \n",
    "        class_name = [key for key, value in class_dict.items() if value == class_id][0]\n",
    "        xmin, ymin, xmax, ymax = yolo2bbox((w, h), yolo_box)\n",
    "        \n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        \n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Annotate the bounding box with class name\n",
    "        plt.text(xmin, ymin - 5, class_name, color='r', fontsize=8, ha='center', va='bottom')\n",
    "    \n",
    "    plt.title(f\"Image {i}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
